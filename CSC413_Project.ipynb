{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CSC413-Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rutavshah/CSC413_Project/blob/main/CSC413_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5beOv8BC_fA"
      },
      "source": [
        "# Importing in MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x57Zaj7qQmx"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def dataloader(batch_size):\n",
        "  dataroot=\"/content/drive/My Drive/celeba\"\n",
        "  transform=transforms.Compose([ transforms.Resize(64),transforms.CenterCrop(64),transforms.ToTensor(),transforms.Normalize((0.5),(0.5))])\n",
        "  dataset=torchvision.datasets.MNIST(root=dataroot, train=True, transform=transform, download=True)\n",
        "  data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "  return data_loader\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLQvGAMmDDat"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP4dl6tjECWa"
      },
      "source": [
        "from torchvision.utils import make_grid , save_image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def show_and_save(file_name,img):\n",
        "    npimg = np.transpose(img.numpy(),(1,2,0))\n",
        "    # f = \"./%s.png\" % file_name\n",
        "    fig = plt.figure(dpi=200)\n",
        "    fig.suptitle(file_name, fontsize=14, fontweight='bold')\n",
        "    plt.imshow(npimg)\n",
        "    # plt.imsave(f,npimg)\n",
        "def plot_loss(loss_list):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.title(\"Loss During Training\")\n",
        "    plt.plot(loss_list,label=\"Loss\")\n",
        "    \n",
        "    plt.xlabel(\"iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuzjHgDEDHNF"
      },
      "source": [
        "# Decoder, Encoder/Generator, Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yH0G0dJD8Hw"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Encoder,self).__init__()\n",
        "    self.conv1=nn.Conv2d(1,64,5,padding=2,stride=2)   #in_channels=3\n",
        "    self.bn1=nn.BatchNorm2d(64,momentum=0.9)\n",
        "    self.conv2=nn.Conv2d(64,128,5,padding=2,stride=2)\n",
        "    self.bn2=nn.BatchNorm2d(128,momentum=0.9)\n",
        "    self.conv3=nn.Conv2d(128,256,5,padding=2,stride=2)\n",
        "    self.bn3=nn.BatchNorm2d(256,momentum=0.9)\n",
        "    self.relu=nn.LeakyReLU(0.2)\n",
        "    self.fc1=nn.Linear(256*8*8,2048)\n",
        "    self.bn4=nn.BatchNorm1d(2048,momentum=0.9)\n",
        "    self.fc_mean=nn.Linear(2048,128)\n",
        "    self.fc_logvar=nn.Linear(2048,128)   #latent dim=128\n",
        "  \n",
        "  def forward(self,x):\n",
        "    batch_size=x.size()[0]\n",
        "    out=self.relu(self.bn1(self.conv1(x)))\n",
        "    out=self.relu(self.bn2(self.conv2(out)))\n",
        "    out=self.relu(self.bn3(self.conv3(out)))\n",
        "    out=out.view(batch_size,-1)\n",
        "    out=self.relu(self.bn4(self.fc1(out)))\n",
        "    mean=self.fc_mean(out)\n",
        "    logvar=self.fc_logvar(out)\n",
        "    \n",
        "    return mean,logvar\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Decoder,self).__init__()\n",
        "    self.fc1=nn.Linear(128,8*8*256)\n",
        "    self.bn1=nn.BatchNorm1d(8*8*256,momentum=0.9)\n",
        "    self.relu=nn.LeakyReLU(0.2)\n",
        "    self.deconv1=nn.ConvTranspose2d(256,256,6, stride=2, padding=2)\n",
        "    self.bn2=nn.BatchNorm2d(256,momentum=0.9)\n",
        "    self.deconv2=nn.ConvTranspose2d(256,128,6, stride=2, padding=2)\n",
        "    self.bn3=nn.BatchNorm2d(128,momentum=0.9)\n",
        "    self.deconv3=nn.ConvTranspose2d(128,32,6, stride=2, padding=2)\n",
        "    self.bn4=nn.BatchNorm2d(32,momentum=0.9)\n",
        "    self.deconv4=nn.ConvTranspose2d(32,1,5, stride=1, padding=2)\n",
        "    self.tanh=nn.Tanh()\n",
        "\n",
        "  def forward(self,x):\n",
        "    batch_size=x.size()[0]\n",
        "    x=self.relu(self.bn1(self.fc1(x)))\n",
        "    x=x.view(-1,256,8,8)\n",
        "    x=self.relu(self.bn2(self.deconv1(x)))\n",
        "    x=self.relu(self.bn3(self.deconv2(x)))\n",
        "    x=self.relu(self.bn4(self.deconv3(x)))\n",
        "    x=self.tanh(self.deconv4(x))\n",
        "    return x\n",
        "    \n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator,self).__init__()\n",
        "    self.conv1=nn.Conv2d(1,32,5,padding=2,stride=1)\n",
        "    self.relu=nn.LeakyReLU(0.2)\n",
        "    self.conv2=nn.Conv2d(32,128,5,padding=2,stride=2)\n",
        "    self.bn1=nn.BatchNorm2d(128,momentum=0.9)\n",
        "    self.conv3=nn.Conv2d(128,256,5,padding=2,stride=2)\n",
        "    self.bn2=nn.BatchNorm2d(256,momentum=0.9)\n",
        "    self.conv4=nn.Conv2d(256,256,5,padding=2,stride=2)\n",
        "    self.bn3=nn.BatchNorm2d(256,momentum=0.9)\n",
        "    self.fc1=nn.Linear(8*8*256,512)\n",
        "    self.bn4=nn.BatchNorm1d(512,momentum=0.9)\n",
        "    self.fc2=nn.Linear(512,1)\n",
        "    self.sigmoid=nn.Sigmoid()\n",
        "\n",
        "  def forward(self,x):\n",
        "    batch_size=x.size()[0]\n",
        "    x=self.relu(self.conv1(x))\n",
        "    x=self.relu(self.bn1(self.conv2(x)))\n",
        "    x=self.relu(self.bn2(self.conv3(x)))\n",
        "    x=self.relu(self.bn3(self.conv4(x)))\n",
        "    x=x.view(-1,256*8*8)\n",
        "    x1=x;\n",
        "    x=self.relu(self.bn4(self.fc1(x)))\n",
        "    x=self.sigmoid(self.fc2(x))\n",
        "\n",
        "    return x,x1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XO2bxzuDDUbj"
      },
      "source": [
        "# VAE-GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-e4Ya7mnD6FW"
      },
      "source": [
        "class VAE_GAN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(VAE_GAN,self).__init__()\n",
        "    self.encoder=Encoder()\n",
        "    self.decoder=Decoder()\n",
        "    self.discriminator=Discriminator()\n",
        "    self.encoder.apply(weights_init)\n",
        "    self.decoder.apply(weights_init)\n",
        "    self.discriminator.apply(weights_init)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    bs=x.size()[0]\n",
        "    z_mean,z_logvar=self.encoder(x)\n",
        "    std = z_logvar.mul(0.5).exp_()\n",
        "        \n",
        "    #sampling epsilon from normal distribution\n",
        "    epsilon=torch.randn(bs,128).to(device)\n",
        "    z=z_mean+std*epsilon\n",
        "    x_tilda=self.decoder(z)\n",
        "      \n",
        "    return z_mean,z_logvar,x_tilda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu23XWLHDWz8"
      },
      "source": [
        "# GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNZAmpBc1TX-"
      },
      "source": [
        "class GAN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(GAN,self).__init__()\n",
        "    self.decoder=Decoder()\n",
        "    self.discriminator=Discriminator()\n",
        "    self.decoder.apply(weights_init)\n",
        "    self.discriminator.apply(weights_init)\n",
        "\n",
        "  def forward(self,z):\n",
        "\n",
        "    x_tilda=self.decoder(z)\n",
        "    x, x1 = self.discriminator(x_tilda)\n",
        "    \n",
        "    return x_tilda, x, x1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q49knUb2Da7Y"
      },
      "source": [
        "# VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT6KZiHx9zhM"
      },
      "source": [
        "class VAE(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(VAE,self).__init__()\n",
        "    self.encoder=Encoder()\n",
        "    self.decoder=Decoder()\n",
        "    self.encoder.apply(weights_init)\n",
        "    self.decoder.apply(weights_init)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    bs=x.size()[0]\n",
        "    z_mean,z_logvar=self.encoder(x)\n",
        "    std = z_logvar.mul(0.5).exp_()\n",
        "        \n",
        "    #sampling epsilon from normal distribution\n",
        "    epsilon=torch.randn(bs,128).to(device)\n",
        "    z=z_mean+std*epsilon\n",
        "    x_tilda=self.decoder(z)\n",
        "      \n",
        "    return z_mean,z_logvar,x_tilda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajxB8k9L-NtW"
      },
      "source": [
        "# Training: VAE-GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GPdInMoq2S7"
      },
      "source": [
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "data_loader=dataloader(64)\n",
        "gen=VAE_GAN().to(device)\n",
        "discrim=Discriminator().to(device)\n",
        "real_batch = next(iter(data_loader))\n",
        "show_and_save(\"training\" ,make_grid((real_batch[0]*0.5+0.5).cpu(),8))\n",
        "\n",
        "epochs=3\n",
        "lr=3e-4\n",
        "alpha=0.1\n",
        "gamma=15\n",
        "\n",
        "# Loss function and Gradient descent algorithms\n",
        "criterion = nn.BCELoss().to(device)\n",
        "optim_E = torch.optim.RMSprop(gen.encoder.parameters(), lr=lr)\n",
        "optim_D = torch.optim.RMSprop(gen.decoder.parameters(), lr=lr)\n",
        "optim_Dis = torch.optim.RMSprop(discrim.parameters(), lr=lr*alpha)\n",
        "\n",
        "z_fixed = torch.randn((64,128)).to(device)\n",
        "x_fixed = real_batch[0].to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  prior_loss_list,gan_loss_list,recon_loss_list=[],[],[]\n",
        "  dis_real_list,dis_fake_list,dis_prior_list=[],[],[]\n",
        "  for i, (data,_) in enumerate(data_loader, 0):\n",
        "    bs=data.size()[0]\n",
        "    \n",
        "    ones_label=torch.ones(bs,1).to(device)\n",
        "    zeros_label=torch.zeros(bs,1).to(device)\n",
        "    zeros_label1=torch.zeros(64,1).to(device)\n",
        "    datav = data.to(device)\n",
        "\n",
        "    mean, logvar, rec_enc = gen(datav)\n",
        "\n",
        "    # Random z that is input for the GAN generator or the VAE-GAN \n",
        "    z_p = torch.randn(64,128).to(device)\n",
        "    x_p_tilda = gen.decoder(z_p)\n",
        " \n",
        "    output = discrim(datav)[0]\n",
        "    errD_real = criterion(output, ones_label)\n",
        "    dis_real_list.append(errD_real.item())\n",
        "\n",
        "    output = discrim(rec_enc)[0]\n",
        "    errD_rec_enc = criterion(output, zeros_label)\n",
        "    dis_fake_list.append(errD_rec_enc.item())\n",
        "\n",
        "    output = discrim(x_p_tilda)[0]\n",
        "    errD_rec_noise = criterion(output, zeros_label1)\n",
        "    dis_prior_list.append(errD_rec_noise.item())\n",
        "\n",
        "    gan_loss = errD_real + errD_rec_enc + errD_rec_noise\n",
        "    gan_loss_list.append(gan_loss.item())\n",
        "\n",
        "    # Gradient descent update for Discrimator\n",
        "    optim_Dis.zero_grad()\n",
        "    gan_loss.backward(retain_graph=True)\n",
        "    optim_Dis.step()\n",
        "\n",
        "\n",
        "    output = discrim(datav)[0]\n",
        "    errD_real = criterion(output, ones_label)\n",
        "\n",
        "    output = discrim(rec_enc)[0]\n",
        "    errD_rec_enc = criterion(output, zeros_label)\n",
        "\n",
        "    output = discrim(x_p_tilda)[0]\n",
        "    errD_rec_noise = criterion(output, zeros_label1)\n",
        "\n",
        "    # GAN Loss\n",
        "    gan_loss = errD_real + errD_rec_enc + errD_rec_noise\n",
        "    \n",
        "    \n",
        "    x_l_tilda = discrim(rec_enc)[1]\n",
        "    x_l = discrim(datav)[1]\n",
        "    rec_loss = ((x_l_tilda - x_l) ** 2).mean()\n",
        "    err_dec = gamma * rec_loss - gan_loss \n",
        "    recon_loss_list.append(rec_loss.item())\n",
        "\n",
        "    # Gradient descent update for Decoder/Generator\n",
        "    optim_D.zero_grad()\n",
        "    err_dec.backward(retain_graph=True)\n",
        "    optim_D.step()\n",
        "    \n",
        "    mean, logvar, rec_enc = gen(datav)\n",
        "    x_l_tilda = discrim(rec_enc)[1]\n",
        "    x_l = discrim(datav)[1]\n",
        "    rec_loss = ((x_l_tilda - x_l) ** 2).mean()\n",
        "    prior_loss = 1 + logvar - mean.pow(2) - logvar.exp()\n",
        "    prior_loss = (-0.5 * torch.sum(prior_loss))/torch.numel(mean.data)\n",
        "    prior_loss_list.append(prior_loss.item())\n",
        "    err_enc = prior_loss + 5*rec_loss\n",
        "\n",
        "    # Gradient descent update for Encoder\n",
        "    optim_E.zero_grad()\n",
        "    err_enc.backward(retain_graph=True)\n",
        "    optim_E.step()\n",
        "    \n",
        "    if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_gan: %.4f\\tLoss_prior: %.4f\\tRec_loss: %.4f\\tdis_real_loss: %0.4f\\tdis_fake_loss: %.4f\\tdis_prior_loss: %.4f'\n",
        "                  % (epoch,epochs, i, len(data_loader),\n",
        "                     gan_loss.item(), prior_loss.item(),rec_loss.item(),errD_real.item(),errD_rec_enc.item(),errD_rec_noise.item()))\n",
        "\n",
        "  b=gen(x_fixed)[2]\n",
        "  b=b.detach()\n",
        "  c=gen.decoder(z_fixed)\n",
        "  c=c.detach()\n",
        "  show_and_save('MNISTrec_noise_epoch_%d.png' % epoch ,make_grid((c*0.5+0.5).cpu(),8))\n",
        "  show_and_save('MNISTrec_epoch_%d.png' % epoch ,make_grid((b*0.5+0.5).cpu(),8))\n",
        "\n",
        "plot_loss(prior_loss_list)\n",
        "plot_loss(recon_loss_list)\n",
        "plot_loss(gan_loss_list)\n",
        "torch.save(gen.state_dict(), '/content/gen' )\n",
        "torch.save(discrim.state_dict(),'/content/discrim' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JZA145l-UJ3"
      },
      "source": [
        "# Training: GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UhwLX01TES7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed8dec9c-f574-4cc6-f543-0f3ac0ddfe37"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "data_loader=dataloader(64)\n",
        "\n",
        "gan = GAN().to(device)\n",
        "real_batch = next(iter(data_loader))\n",
        "# show_and_save(\"training\" ,make_grid((real_batch[0]*0.5+0.5).cpu(),8))\n",
        "\n",
        "epochs=1\n",
        "lr=0.04\n",
        "alpha=0.1\n",
        "gamma=15\n",
        "iters_d = 2\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.BCELoss().to(device)\n",
        "\n",
        "# Gradient Descent algorithms\n",
        "GAN_optim_Gen = torch.optim.RMSprop(gan.decoder.parameters(), lr=lr)\n",
        "GAN_optim_Dis = torch.optim.RMSprop(gan.discriminator.parameters(), lr=lr*alpha)\n",
        "\n",
        "for epoch in range(epochs):\n",
        " \n",
        "  for i, (data,_) in enumerate(data_loader, 0):\n",
        "    bs=data.size()[0]\n",
        "    \n",
        "    ones_label=torch.ones(bs,1).to(device)\n",
        "    zeros_label=torch.zeros(bs,1).to(device)\n",
        "    zeros_label1=torch.zeros(64,1).to(device)\n",
        "    datav = data.to(device)\n",
        "\n",
        "    # Training step for the Discriminator\n",
        "    for j in range(iters_d):\n",
        "      z = torch.randn(64,128).to(device)\n",
        "      x_tilde, x, x1 = gan(z)\n",
        "      x_real, x2 = gan.discriminator(datav)\n",
        "\n",
        "      # Loss for Discriminator\n",
        "      dis_loss =  criterion(x_real, ones_label) + criterion(x, zeros_label1)\n",
        "\n",
        "      # Gradient Descent update for the Discriminator\n",
        "      GAN_optim_Dis.zero_grad()\n",
        "      dis_loss.backward(retain_graph=True)\n",
        "      GAN_optim_Dis.step()\n",
        "\n",
        "    # Training step for the Generator\n",
        "\n",
        "    z = torch.randn(64,128).to(device)\n",
        "    x_tilde, x, x1 = gan(z)\n",
        "\n",
        "    # Loss for Generator\n",
        "    gen_loss = criterion(x, zeros_label1)\n",
        "\n",
        "    # Gradient Descent update for the Generator\n",
        "    GAN_optim_Gen.zero_grad()\n",
        "    gen_loss.backward(retain_graph=True)\n",
        "    GAN_optim_Gen.step()\n",
        "\n",
        "\n",
        "    if i % 50 == 0:\n",
        "      print(\"[%d/%d][%d/%d]\" % (epoch,epochs, i, len(data_loader)))\n",
        "\n",
        "torch.save(gan.state_dict(), '/content/GAN_model' )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0/1][0/938]\n",
            "[0/1][50/938]\n",
            "[0/1][100/938]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bmNzB9j-WvJ"
      },
      "source": [
        "# Training: VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ULmUGUeoleW"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "data_loader=dataloader(64)\n",
        "\n",
        "vae = VAE().to(device)\n",
        "real_batch = next(iter(data_loader))\n",
        "# show_and_save(\"training\" ,make_grid((real_batch[0]*0.5+0.5).cpu(),8))\n",
        "\n",
        "epochs=1\n",
        "lr=3e-4\n",
        "alpha=0.1\n",
        "gamma=15\n",
        "\n",
        "VAE_optim = torch.optim.RMSprop(vae.parameters(), lr=lr)\n",
        "\n",
        "for epoch in range(epochs):\n",
        " \n",
        "  for i, (data,_) in enumerate(data_loader, 0):\n",
        "    bs=data.size()[0]\n",
        "\n",
        "    datav = data.to(device)\n",
        "\n",
        "    z_mean,z_logvar,x_tilda = vae(datav)\n",
        "\n",
        "    # Calculating the loss (Element wise and KLD)\n",
        "    rec_loss = ((x_tilda - datav) ** 2).mean()\n",
        "    prior_loss = 1 + z_logvar - z_mean.pow(2) - z_logvar.exp()\n",
        "    prior_loss2 = (-0.5 * torch.sum(prior_loss))/torch.numel(z_mean.data)\n",
        "    err_enc = prior_loss2 + rec_loss\n",
        "\n",
        "    # Gradient descent update\n",
        "    VAE_optim.zero_grad()\n",
        "    err_enc.backward(retain_graph=True)\n",
        "    VAE_optim.step()\n",
        "\n",
        "    if i % 50 == 0:\n",
        "      print(\"[%d/%d][%d/%d]\" % (epoch,epochs, i, len(data_loader)))\n",
        "\n",
        "torch.save(vae.state_dict(), '/content/VAE_model' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBxbN4b4BxTN"
      },
      "source": [
        "# Example: VAE-GAN Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnresw05AreP"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "gen2 = VAE_GAN()\n",
        "gen2.load_state_dict(torch.load('/content/modela', map_location=torch.device(device)))\n",
        "\n",
        "data_loader=dataloader(64)\n",
        "real_batch = next(iter(data_loader))\n",
        "z_fixed = torch.randn((64,128))\n",
        "x_fixed = real_batch[0].to(device)\n",
        "\n",
        "z_mean,z_logvar,x_tilda = gen2(x_fixed)\n",
        "x_tilda=x_tilda.detach()\n",
        "print(x_tilda)\n",
        "\n",
        "show_and_save('MNISTrec_epoch.png'  ,make_grid((x_tilda*0.5+0.5).cpu(),8))\n",
        "# show_and_save('MNISTrec_epoch.png'  ,make_grid((x_fixed*0.5+0.5).cpu(),8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVgAnlCYB4rS"
      },
      "source": [
        "# Example: GAN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEu7VP1_P43v"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "gan2 = GAN()\n",
        "real_batch = next(iter(data_loader))\n",
        "gan2.load_state_dict(torch.load('/content/GAN_model', map_location=torch.device(device)))\n",
        "\n",
        "data_loader=dataloader(64)\n",
        "z_fixed = torch.randn((64,128))\n",
        "x_fixed = real_batch[0].to(device)\n",
        "\n",
        "\n",
        "real_batch = next(iter(data_loader))\n",
        "x_tilda, x, x1 = gan2(z_fixed)\n",
        "x_tilda=x_tilda.detach()\n",
        "print(x_tilda)\n",
        "\n",
        "show_and_save('MNISTrec_epoch.png'  ,make_grid((x_tilda*0.5+0.5).cpu(),8))\n",
        "show_and_save('MNISTrec_epoch.png'  ,make_grid((x_fixed*0.5+0.5).cpu(),8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvvsVKraAURl"
      },
      "source": [
        "# Example: VAE Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmFqsQZ8AFg-"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "vae2 = VAE().to(device)\n",
        "real_batch = next(iter(data_loader))\n",
        "vae2.load_state_dict(torch.load('/content/VAE_model', map_location=torch.device(device)))\n",
        "\n",
        "data_loader=dataloader(64)\n",
        "z_fixed = torch.randn((64,128))\n",
        "x_fixed = real_batch[0].to(device)\n",
        "\n",
        "\n",
        "real_batch = next(iter(data_loader))\n",
        "z_mean,z_logvar,x_tilda = vae2(x_fixed)\n",
        "x_tilda=x_tilda.detach()\n",
        "print(x_tilda)\n",
        "\n",
        "show_and_save('MNISTrec_epoch.png'  ,make_grid((x_tilda*0.5+0.5).cpu(),8))\n",
        "# show_and_save('MNISTrec_epoch.png'  ,make_grid((x_fixed*0.5+0.5).cpu(),8))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}